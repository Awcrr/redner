{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial focuses on the fast local shading mode of redner. This mode does not compute shadow or global illumination, but is faster and less noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will import pyredner and pytorch, download the teapot object, load it, and setup the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyredner\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    "# wget\n",
    "filedata = urllib.request.urlretrieve('https://casual-effects.com/g3d/data10/common/model/teapot/teapot.zip', 'teapot.zip')\n",
    "# unzip\n",
    "zip_ref = zipfile.ZipFile('teapot.zip', 'r')\n",
    "zip_ref.extractall('teapot/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = pyredner.load_obj('teapot/teapot.obj', return_objects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = pyredner.automatic_camera_placement(objects, resolution=(480, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = pyredner.Scene(camera = camera, objects = objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in contrast to the previous tutorials, we also setup some lightings. In the fast local shading mode, redner supports four kinds of lights: ambient light, point light, directional light, and spot light. We setup a point light with squared distance falloff at between the camera and the teapot this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "light = pyredner.PointLight(position = (camera.position + torch.tensor((0.0, 0.0, 100.0))).to(pyredner.get_device()),\n",
    "                                                intensity = torch.tensor((20000.0, 30000.0, 20000.0), device = pyredner.get_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene construction, time: 0.02416 s\n",
      "Forward pass, time: 0.71820 s\n"
     ]
    }
   ],
   "source": [
    "img = pyredner.render_deferred(scene = scene, lights = [light])\n",
    "# Visualize img\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "imshow(img.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the teapot rendering has some weird stripe patterns. This is because the teapot has a low number of polygons, and the normals used to calculate the Lambertian response introduces the pattern to rendering. A remedy for this is to use [Phong normal interpolation](https://en.wikipedia.org/wiki/Phong_shading): we compute a normal field at each vertex on the triangle mesh, and interpolate from the nearby vertices when computing the shading normal. Many Wavefront object files come with vertex normals, but this teapot does not. Redner implements [Nelson Max's algorithm](https://escholarship.org/content/qt7657d8h3/qt7657d8h3.pdf?t=ptt283) for computing the vertex normal. We can attach vertex normals as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in objects:\n",
    "    obj.normals = pyredner.compute_vertex_normal(obj.vertices, obj.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-render the scene, we get a smoother teapot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = pyredner.Scene(camera = camera, objects = objects)\n",
    "img = pyredner.render_deferred(scene = scene, lights = [light])\n",
    "# Visualize img\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "imshow(img.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from point lights, redner also supports ambient light, which is just a multiplier over the albedo values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light = pyredner.AmbientLight(intensity = torch.tensor((0.8, 1.2, 0.8), device = pyredner.get_device()))\n",
    "img = pyredner.render_deferred(scene = scene, lights = [light])\n",
    "# Visualize img\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "imshow(img.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directional lights doesn't exhibit distance falloff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light = pyredner.DirectionalLight(direction = torch.tensor((-1.0, 1.0, 1.0), device = pyredner.get_device()),\n",
    "                                                         intensity = torch.tensor((2.0, 3.0, 2.0), device = pyredner.get_device()))\n",
    "img = pyredner.render_deferred(scene = scene, lights = [light])\n",
    "# Visualize img\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "imshow(img.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And spot light is a directional light with exponential falloff over a direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light = pyredner.SpotLight(position = camera.position.to(pyredner.get_device()),\n",
    "                                               spot_direction = torch.tensor((0.0, 0.0, 1.0), device = pyredner.get_device()),\n",
    "                                               spot_exponent = torch.tensor(100.0, device = pyredner.get_device()),\n",
    "                                               intensity = torch.tensor((2.0, 3.0, 2.0), device = pyredner.get_device()))\n",
    "img = pyredner.render_deferred(scene = scene, lights = [light])\n",
    "# Visualize img\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "imshow(img.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to adapt the deferred shading functionality, such as using materials other than Lambertian, you can write the shading code yourself in PyTorch. redner provides the `render_g_buffer` function to output different channels for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pyredner.render_g_buffer(scene = scene, channels = [pyredner.channels.position,\n",
    "                                                                                                         pyredner.channels.shading_normal,\n",
    "                                                                                                         pyredner.channels.diffuse_reflectance])\n",
    "pos = img[:, :, :3]\n",
    "normal = img[:, :, 3:6]\n",
    "albedo = img[:, :, 6:9]\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "pos_vis = (pos - pos.min()) / (pos.max() - pos.min())\n",
    "imshow(pos_vis.cpu())\n",
    "plt.figure()\n",
    "normal_vis = (normal - normal.min()) / (normal.max() - normal.min())\n",
    "imshow(normal_vis.cpu())\n",
    "plt.figure()\n",
    "imshow(albedo.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
